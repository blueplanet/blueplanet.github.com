## 回归／梯度
- 回归是什么？
    - 数学上的回归：给定一个点集，用曲线去拟合
        - 曲线是直线 -> 线性回归
        - 二次曲线 -> 二次回归
- 回归的目的：通过训练数据去拟合一个函数（假设为`h(x)`，最终使用这个函数来预测分类
- 举例：预测房屋价格
    - 每一个特征值用X1,X2,..Xn来表示（x1：房屋面积，x2：房屋朝向。。。）
    - 对每个特征值，对应会有一个参数来调整该特征值对结果的影响力（重要性）
    - 对各个参数以及作出的函数，有一个评估，这个评估方法／函数被重做损失函数或错误函数，描述h函数不好的程度，假设为`j(参数）`
    - `j(参数)`函数是对每个特征值，使用参数值来估算结果值（房屋价格）后，计算估算结果与实际结果的偏差值
    - 如何调整参数值，使`j(参数)`（错误函数）的结果（即与实际结果相差）最小，有最小二乘法以及梯度下降法
- 梯度下降法
    - 随机或者使用全零对参数进行赋值
    - 改变参数的值，使得`j`按梯度下降的额方向减少
        - 对每一个特征值的参数，都可以求出一个梯度
        - 用所有参数的梯度求出一个整体的方向，就可以朝着下降最多的方向进行变化

## logistic回归

## 问题
- [ ] logistic回归是什么？
- [ ] 梯度下降法
    - 很大程度上受初始点的影响，可能会进入局部最小点，如何解决
    - 步长如何确定？

## 参考链接
- [机器学习中的数学(1)-回归(regression)、梯度下降(gradient descent) - LeftNotEasy - 博客园](http://www.cnblogs.com/LeftNotEasy/archive/2010/12/05/mathmatic_in_machine_learning_1_regression_and_gradient_descent.html)
- [机器学习中的数学(2)-线性回归，偏差、方差权衡 - LeftNotEasy - 博客园](http://www.cnblogs.com/LeftNotEasy/archive/2010/12/19/mathmatic_in_machine_learning_2_regression_and_bias_variance_trade_off.html)

